{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c578154",
   "metadata": {},
   "source": [
    "## Transfer Learning using MobileNetV2 (Cats vs Dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821e813",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037ae1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1821e91",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76665512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\vicky\\Desktop\\CV\\dataset\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"training_set\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"test_set\")\n",
    "\n",
    "print(os.path.exists(TRAIN_DIR), os.path.exists(TEST_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086cdb5",
   "metadata": {},
   "source": [
    "## Step 3: Image Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ceda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487be2e1",
   "metadata": {},
   "source": [
    "## Step 4: Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61831649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f83533",
   "metadata": {},
   "source": [
    "## Step 5: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31988958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b12d2",
   "metadata": {},
   "source": [
    "## Step 6: Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb1d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(160,160,3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639cd7c",
   "metadata": {},
   "source": [
    "## Step 7: Build Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfe4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "model_tl = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382868e",
   "metadata": {},
   "source": [
    "## Step 8: Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6126da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_160 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,081</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,081\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,097</span> (641.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,097\u001b[0m (641.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_tl.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d2e73",
   "metadata": {},
   "source": [
    "## Step 9: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "909c09db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 632ms/step - accuracy: 0.9587 - loss: 0.1005 - val_accuracy: 0.9763 - val_loss: 0.0598\n",
      "Epoch 2/5\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 273ms/step - accuracy: 0.9796 - loss: 0.0568 - val_accuracy: 0.9763 - val_loss: 0.0648\n",
      "Epoch 3/5\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 274ms/step - accuracy: 0.9793 - loss: 0.0508 - val_accuracy: 0.9743 - val_loss: 0.0683\n",
      "Epoch 4/5\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.9888 - loss: 0.0347 - val_accuracy: 0.9778 - val_loss: 0.0673\n",
      "Epoch 5/5\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 285ms/step - accuracy: 0.9904 - loss: 0.0253 - val_accuracy: 0.9753 - val_loss: 0.0715\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "history_tl = model_tl.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    validation_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcd28a",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e020dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 219ms/step - accuracy: 0.9753 - loss: 0.0715\n",
      "Test Accuracy: 97.53%\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL 2: Transfer Learning with MobileNetV2\n",
    "# This code cell is part of the practical and is commented for clarity.\n",
    "\n",
    "\n",
    "loss, acc = model_tl.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa77b6",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "The transfer learning model was successfully implemented using a pre-trained convolutional neural network. By leveraging learned features from a large-scale dataset, the model achieved stable and efficient learning on the target image dataset. The training process showed improved convergence speed and reliable accuracy, demonstrating the effectiveness of transfer learning for image classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5e63d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this practical, transfer learning was applied using a pre-trained deep learning model to perform image classification. The experiment illustrated how pre-trained networks can significantly reduce training time while maintaining strong performance. This practical enhanced the understanding of fine-tuning, feature reuse, and practical deployment of deep learning models. Transfer learning proves to be an efficient approach for solving real-world computer vision problems with limited data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "title": "Practical 2 - Transfer Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
